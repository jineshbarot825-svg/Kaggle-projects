{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62878a19",
   "metadata": {
    "papermill": {
     "duration": 0.005219,
     "end_time": "2025-11-26T17:49:49.974649",
     "exception": false,
     "start_time": "2025-11-26T17:49:49.969430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ===============================================\n",
    "# ðŸ† Project: The \"Kaggle-Concierge\" Swarm\n",
    "# ===============================================\n",
    "### **Track: Concierge Agents ðŸ¤–**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8756559",
   "metadata": {
    "papermill": {
     "duration": 0.003847,
     "end_time": "2025-11-26T17:49:49.982634",
     "exception": false,
     "start_time": "2025-11-26T17:49:49.978787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1. Your New Assistant: The \"Kaggle-Concierge\" Pitch**\n",
    "\n",
    "**The Problem:** Data scientists on Kaggle spend a lot of time on repetitive \"setup\" tasks for every new project: creating folder structures (`/data`, `/notebooks`, `/submission`), downloading datasets, and keeping track of which projects are in which stage.\n",
    "\n",
    "**The Solution:** \"The 'Kaggle-Concierge'\" is a personal AI assistant swarm. The data scientist (user) gives a (mocked) high-level command like `\"start new project: 'Titanic'\"` or `\"download dataset: 'House Prices'\"` to a queue.\n",
    "\n",
    "The swarm activates:\n",
    "1.  A **Sequential** `PlannerAgent` picks up the new command.\n",
    "2.  A **Parallel Team** of specialist agents (`FolderAgent`, `DatasetAgent`) execute the setup tasks *at the same time*.\n",
    "3.  The agents use **Mocked Tools** (`tool_create_folders`, `tool_download_dataset`) to simulate these actions.\n",
    "4.  An **Evaluation Agent** (the `DashboardAgent`) acts as the \"brain.\" It reads reports from the specialists and **generates** a new status update.\n",
    "5.  This \"brain\" agent then uses a **Real Custom Tool** (`tool_update_dashboard`) to **write** the new project's status to a `PROJECT_DASHBOARD.md` file.\n",
    "6.  This `PROJECT_DASHBOARD.md` file acts as the **Stateful Long-Term Memory**, which the agent reads from and writes to, keeping a permanent log of all projects.\n",
    "\n",
    "This project creates a \"personal assistant\" that automates the tedious parts of data science, letting the user focus on building models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79515995",
   "metadata": {
    "papermill": {
     "duration": 0.003705,
     "end_time": "2025-11-26T17:49:49.990191",
     "exception": false,
     "start_time": "2025-11-26T17:49:49.986486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2. The Assistant's Skills**\n",
    "\n",
    "This notebook is a capstone project that demonstrates all 6 key concepts:\n",
    "\n",
    "1.  **Multi-agent System:**\n",
    "    * **Sequential Agents:** `PlannerAgent` -> (Parallel Team) -> `DashboardAgent` (the \"Brain\").\n",
    "    * **Parallel Agents:** `FolderAgent` and `DatasetAgent` run at the same time to set up the project faster.\n",
    "    * **Loop Agent:** The main `run_concierge_swarm` function acts as a \"daemon\" loop, processing a queue of user commands.\n",
    "\n",
    "2.  **Tools:**\n",
    "    * **Mocked Built-in Tool:** `tool_create_folders` simulates creating a directory structure.\n",
    "    * **Mocked Built-in Tool:** `tool_download_dataset` simulates downloading a `.csv` file from Kaggle.\n",
    "    * **Real Custom Tool:** `tool_update_dashboard` saves the final, formatted project status to a `PROJECT_DASHBOARD.md` file.\n",
    "\n",
    "3.  **Long-Running Operations (Pause/Resume):**\n",
    "    * The main swarm function is a **Loop** that processes the `command_queue` and then \"pauses\" (`time.sleep`) to wait for new user commands.\n",
    "\n",
    "4.  **Long-Term Memory (Stateful & File-Based):**\n",
    "    * This project uses the file system itself as its Long-Term Memory.\n",
    "    * **Stateful Read/Write:** The `DashboardAgent` **reads** the `MEMORY_BANK` (a Python dict) for the current state, and then uses its **Real Custom Tool** to **write** the *new* state to the `PROJECT_DASHBOARD.md` file, creating a persistent, stateful log.\n",
    "\n",
    "5.  **Agent Evaluation (The \"Brain\"):**\n",
    "    * The `DashboardAgent` is the \"brain.\" It reads and evaluates the reports from the parallel agents (`{\"status\": \"folders_created\"}`), *synthesizes* them into a new project status, and *generates* a new Markdown-formatted string for the dashboard.\n",
    "\n",
    "6.  **Observability:**\n",
    "    * A `log_message()` function provides a rich, real-time log of every agent's actions and decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6866b",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-11-26T17:49:49.997652",
     "exception": false,
     "start_time": "2025-11-26T17:49:49.993931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **3. The Playbook: System Architecture**\n",
    "\n",
    "This swarm operates on a Sequential -> Parallel -> Sequential workflow.\n",
    "\n",
    "\n",
    "1.  **[LOOP START]** (`run_concierge_swarm`)\n",
    "    * `PlannerAgent` pulls one `command` from the (mocked) queue (e.g., `{'action': 'new_project', 'name': 'Titanic'}`).\n",
    "\n",
    "2.  **[PARALLEL TEAM]** (Specialists)\n",
    "    * The `PlannerAgent` passes the `command` to two specialists who run at the *same time*:\n",
    "        * `FolderAgent`: Uses the (mocked) `tool_create_folders` tool.\n",
    "        * `DatasetAgent`: Uses the (mocked) `tool_download_dataset` tool.\n",
    "\n",
    "3.  **[SEQUENTIAL 2]** (`DashboardAgent` - The \"Brain\")\n",
    "    * Waits for both parallel agents to finish.\n",
    "    * **Evaluates** their reports (e.g., \"folders_created\", \"dataset_downloaded\").\n",
    "    * **Generates** a new `status_message` (e.g., \"Project 'Titanic' is ready. Data at 'mock_data/titanic.csv'\").\n",
    "    * **Writes** this status to `MEMORY_BANK[\"projects\"]` (Stateful Memory).\n",
    "    * Uses its **Real Custom Tool** to save the *entire* `MEMORY_BANK` project list to `PROJECT_DASHBOARD.md`.\n",
    "\n",
    "4.  **[LOOP END]**\n",
    "    * The swarm **pauses** (`time.sleep`) and waits for the next user command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86765029",
   "metadata": {
    "papermill": {
     "duration": 0.003762,
     "end_time": "2025-11-26T17:49:50.005174",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.001412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **3. The Playbook: System Architecture**\n",
    "\n",
    "This swarm operates on a Sequential -> Parallel -> Sequential workflow.\n",
    "\n",
    "\n",
    "1.  **[LOOP START]** (`run_concierge_swarm`)\n",
    "    * `PlannerAgent` pulls one `command` from the (mocked) queue (e.g., `{'action': 'new_project', 'name': 'Titanic'}`).\n",
    "\n",
    "2.  **[PARALLEL TEAM]** (Specialists)\n",
    "    * The `PlannerAgent` passes the `command` to two specialists who run at the *same time*:\n",
    "        * `FolderAgent`: Uses the (mocked) `tool_create_folders` tool.\n",
    "        * `DatasetAgent`: Uses the (mocked) `tool_download_dataset` tool.\n",
    "\n",
    "3.  **[SEQUENTIAL 2]** (`DashboardAgent` - The \"Brain\")\n",
    "    * Waits for both parallel agents to finish.\n",
    "    * **Evaluates** their reports (e.g., \"folders_created\", \"dataset_downloaded\").\n",
    "    * **Generates** a new `status_message` (e.g., \"Project 'Titanic' is ready. Data at 'mock_data/titanic.csv'\").\n",
    "    * **Writes** this status to `MEMORY_BANK[\"projects\"]` (Stateful Memory).\n",
    "    * Uses its **Real Custom Tool** to save the *entire* `MEMORY_BANK` project list to `PROJECT_DASHBOARD.md`.\n",
    "\n",
    "4.  **[LOOP END]**\n",
    "    * The swarm **pauses** (`time.sleep`) and waits for the next user command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfac50d",
   "metadata": {
    "papermill": {
     "duration": 0.003661,
     "end_time": "2025-11-26T17:49:50.012534",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.008873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **ðŸ“š Table of Contents**\n",
    "\n",
    "* **1. Your New Assistant:** The \"Kaggle-Concierge\" Pitch\n",
    "* **2. The Assistant's Skills:** Hackathon Features\n",
    "* **3. The Playbook:** System Architecture\n",
    "* **4. The \"Office\":** Setup (Imports & Memory)\n",
    "* **5. The \"Rolodex\":** The Agent Toolbox\n",
    "* **6. \"Hiring\" the Team (Part 1: The \"Doers\")**\n",
    "* **7. \"Hiring\" the Team (Part 2: The \"Manager\")**\n",
    "* **8. \"Opening for Business\":** The Main Loop\n",
    "* **9. ðŸš€ \"Putting in a Request!\" ðŸš€ (Run Swarm)**\n",
    "* **10. \"Checking the Files\":** (Reviewing the Memory)\n",
    "* **11. ðŸ”” \"Your Dashboard is Ready!\" ðŸ”” (The Final File)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e2e864",
   "metadata": {
    "papermill": {
     "duration": 0.00412,
     "end_time": "2025-11-26T17:49:50.020398",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.016278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **4. The \"Office\": Setup (Imports & Memory)**\n",
    "(This covers Cell 1: Imports and Cell 2: Memory Bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4bc681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.029617Z",
     "iopub.status.busy": "2025-11-26T17:49:50.029269Z",
     "iopub.status.idle": "2025-11-26T17:49:50.038111Z",
     "shell.execute_reply": "2025-11-26T17:49:50.037095Z"
    },
    "papermill": {
     "duration": 0.015348,
     "end_time": "2025-11-26T17:49:50.039562",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.024214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1: Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import textwrap # Used for formatting our final Markdown report\n",
    "\n",
    "print(\"Cell 1: Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0d5fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.049788Z",
     "iopub.status.busy": "2025-11-26T17:49:50.049043Z",
     "iopub.status.idle": "2025-11-26T17:49:50.055505Z",
     "shell.execute_reply": "2025-11-26T17:49:50.054462Z"
    },
    "papermill": {
     "duration": 0.013358,
     "end_time": "2025-11-26T17:49:50.056989",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.043631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 2: Global Memory Bank and Logger initialized.\n"
     ]
    }
   ],
   "source": [
    "MEMORY_BANK = {\n",
    "    # This dictionary will hold the state of all our projects\n",
    "    # e.g., {\"Titanic\": \"Ready\", \"House Prices\": \"Downloading\"}\n",
    "    \"projects\": {},\n",
    "    \"dashboard_file\": \"PROJECT_DASHBOARD.md\",\n",
    "    \"tasks_completed\": 0,\n",
    "}\n",
    "\n",
    "# This helper function will act as our Observability/Logging\n",
    "def log_message(agent_name, message, level=\"INFO\"):\n",
    "    \"\"\"Helper function for formatted logging.\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] [{agent_name}] [{level}]: {message}\")\n",
    "\n",
    "print(\"Cell 2: Global Memory Bank and Logger initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f10e7",
   "metadata": {
    "papermill": {
     "duration": 0.004189,
     "end_time": "2025-11-26T17:49:50.065318",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.061129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **5. The \"Rolodex\": The Agent Toolbox**\n",
    "(This covers Cell 3: Tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea33c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.074800Z",
     "iopub.status.busy": "2025-11-26T17:49:50.074518Z",
     "iopub.status.idle": "2025-11-26T17:49:50.083946Z",
     "shell.execute_reply": "2025-11-26T17:49:50.082775Z"
    },
    "papermill": {
     "duration": 0.016175,
     "end_time": "2025-11-26T17:49:50.085466",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.069291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 3: All tools (mocked and custom) are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Mocked Built-in Tool (File System) ---\n",
    "def tool_create_folders(project_name: str) -> str:\n",
    "    \"\"\"MOCK BUILT-IN TOOL: Simulates creating a project folder structure.\"\"\"\n",
    "    log_message(\"FileSystemTool\", f\"Creating folders for '{project_name}': /data, /notebooks, /submission\")\n",
    "    # Simulate a small delay\n",
    "    time.sleep(0.1) \n",
    "    return \"folders_created\"\n",
    "\n",
    "# --- Mocked Built-in Tool (Networking) ---\n",
    "def tool_download_dataset(dataset_name: str) -> str:\n",
    "    \"\"\"MOCK BUILT-IN TOOL: Simulates downloading a dataset from Kaggle.\"\"\"\n",
    "    log_message(\"NetworkTool\", f\"Downloading dataset '{dataset_name}' from Kaggle...\")\n",
    "    # Simulate a longer delay for downloading\n",
    "    time.sleep(0.5) \n",
    "    mock_path = f\"mock_data/{dataset_name.lower().replace(' ', '_')}.csv\"\n",
    "    log_message(\"NetworkTool\", f\"Dataset saved to '{mock_path}'\")\n",
    "    return mock_path\n",
    "\n",
    "# --- REAL Custom Tool (Markdown File Saver) ---\n",
    "def tool_update_dashboard(project_dict: dict, filename: str):\n",
    "    \"\"\"\n",
    "    REAL CUSTOM TOOL: Saves the entire project dictionary to a\n",
    "    formatted Markdown dashboard file. This is our stateful LTM.\n",
    "    \"\"\"\n",
    "    log_message(\"DashboardTool\", f\"Updating stateful dashboard file: '{filename}'\")\n",
    "    try:\n",
    "        # Generate the Markdown content\n",
    "        content = \"# ðŸ¤– Kaggle-Concierge Project Dashboard\\n\\n\"\n",
    "        content += \"Current status of all data science projects.\\n\\n\"\n",
    "        content += \"| Project Name | Status |\\n\"\n",
    "        content += \"| :--- | :--- |\\n\"\n",
    "        \n",
    "        if not project_dict:\n",
    "            content += \"| (No projects started) | - |\\n\"\n",
    "        else:\n",
    "            for project, status in project_dict.items():\n",
    "                content += f\"| **{project}** | {status} |\\n\"\n",
    "        \n",
    "        # Write the file\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(content)\n",
    "            \n",
    "        log_message(\"DashboardTool\", \"Dashboard successfully updated.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(\"DashboardTool\", f\"Failed to update dashboard: {e}\", level=\"ERROR\")\n",
    "\n",
    "print(\"Cell 3: All tools (mocked and custom) are defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e52044",
   "metadata": {
    "papermill": {
     "duration": 0.003919,
     "end_time": "2025-11-26T17:49:50.093617",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.089698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **6. \"Hiring\" the Team (Part 1: The \"Doers\")**\n",
    "(This covers Cell 4: Specialists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe47e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.103581Z",
     "iopub.status.busy": "2025-11-26T17:49:50.103171Z",
     "iopub.status.idle": "2025-11-26T17:49:50.110850Z",
     "shell.execute_reply": "2025-11-26T17:49:50.109804Z"
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2025-11-26T17:49:50.112234",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.097877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 4: Planner and Parallel Specialist Agents defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Sequential Agent 1: The Planner ---\n",
    "def planner_agent(command: dict) -> dict:\n",
    "    \"\"\"SEQUENTIAL AGENT 1: Logs the new command and passes it to the team.\"\"\"\n",
    "    log_message(\"PlannerAgent\", f\"New command received: {command['action']} for '{command['name']}'\")\n",
    "    return {\"command\": command}\n",
    "\n",
    "# --- Parallel Agent 1: The Folder Agent ---\n",
    "def folder_agent(command: dict) -> dict:\n",
    "    \"\"\"PARALLEL AGENT 1: Creates the project folder structure.\"\"\"\n",
    "    log_message(\"FolderAgent\", f\"Activating for project '{command['name']}'\")\n",
    "    \n",
    "    if command[\"action\"] != \"new_project\":\n",
    "        log_message(\"FolderAgent\", \"No folder action required. Skipping.\")\n",
    "        return {\"folder_status\": \"skipped\"}\n",
    "        \n",
    "    # Use the (mocked) tool\n",
    "    status = tool_create_folders(command[\"name\"])\n",
    "    \n",
    "    log_message(\"FolderAgent\", \"Folder creation complete.\")\n",
    "    return {\"folder_status\": status}\n",
    "\n",
    "# --- Parallel Agent 2: The Dataset Agent ---\n",
    "def dataset_agent(command: dict) -> dict:\n",
    "    \"\"\"PARALLEL AGENT 2: Downloads the relevant dataset.\"\"\"\n",
    "    log_message(\"DatasetAgent\", f\"Activating for project '{command['name']}'\")\n",
    "    \n",
    "    # Use the (mocked) tool\n",
    "    dataset_path = tool_download_dataset(command[\"name\"])\n",
    "    \n",
    "    log_message(\"DatasetAgent\", \"Dataset download complete.\")\n",
    "    return {\"dataset_status\": \"downloaded\", \"path\": dataset_path}\n",
    "\n",
    "print(\"Cell 4: Planner and Parallel Specialist Agents defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76eff03",
   "metadata": {
    "papermill": {
     "duration": 0.004049,
     "end_time": "2025-11-26T17:49:50.120625",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.116576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **7. \"Hiring\" the Team (Part 2: The \"Manager\")**\n",
    "(This covers Cell 5: The \"Brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3b2bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.129986Z",
     "iopub.status.busy": "2025-11-26T17:49:50.129671Z",
     "iopub.status.idle": "2025-11-26T17:49:50.137397Z",
     "shell.execute_reply": "2025-11-26T17:49:50.135958Z"
    },
    "papermill": {
     "duration": 0.014462,
     "end_time": "2025-11-26T17:49:50.139000",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.124538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 5: Evaluation ('Brain') Agent defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation Agent: The \"Brain\" ---\n",
    "def dashboard_agent(command: dict, folder_report: dict, dataset_report: dict) -> dict:\n",
    "    \"\"\"\n",
    "    EVALUATION AGENT: The \"brain.\"\n",
    "    Synthesizes reports from the parallel team into one status update.\n",
    "    Demonstrates: Agent Evaluation, Generative AI (Mocked), LTM (Write)\n",
    "    \"\"\"\n",
    "    project_name = command['name']\n",
    "    log_message(\"DashboardAgent\", f\"Synthesizing all reports for project '{project_name}'...\")\n",
    "    \n",
    "    # --- MOCKED GENERATIVE AI (Evaluation & Generation Logic) ---\n",
    "    \n",
    "    # 1. Evaluate the reports\n",
    "    f_status = folder_report[\"folder_status\"]\n",
    "    d_status = dataset_report[\"dataset_status\"]\n",
    "    \n",
    "    # 2. Generate a new, human-readable status message\n",
    "    new_status = \"\"\n",
    "    if f_status == \"folders_created\" and d_status == \"downloaded\":\n",
    "        new_status = f\"Project Ready. Data at: {dataset_report['path']}\"\n",
    "    elif f_status == \"skipped\" and d_status == \"downloaded\":\n",
    "        new_status = f\"Data Ready. Path: {dataset_report['path']}\"\n",
    "    else:\n",
    "        # Fallback for any other combo\n",
    "        new_status = f\"Tasks complete. Folders: {f_status}, Data: {d_status}\"\n",
    "        \n",
    "    log_message(\"DashboardAgent\", f\"Generated new status: {new_status}\")\n",
    "    \n",
    "    # --- LONG-TERM MEMORY (WRITE) ---\n",
    "    # 3. Write this new status to our in-memory state\n",
    "    MEMORY_BANK[\"projects\"][project_name] = new_status\n",
    "    MEMORY_BANK[\"tasks_completed\"] += 1\n",
    "    \n",
    "    # 4. Use the REAL Custom Tool to save the *entire* state to the .md file\n",
    "    tool_update_dashboard(\n",
    "        project_dict=MEMORY_BANK[\"projects\"],\n",
    "        filename=MEMORY_BANK[\"dashboard_file\"]\n",
    "    )\n",
    "    \n",
    "    return {\"final_status\": new_status}\n",
    "\n",
    "print(\"Cell 5: Evaluation ('Brain') Agent defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa5266",
   "metadata": {
    "papermill": {
     "duration": 0.004148,
     "end_time": "2025-11-26T17:49:50.147376",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.143228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **8. \"Opening for Business\": The Main Loop**\n",
    "(This covers Cell 6: Main Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccb7a368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.157565Z",
     "iopub.status.busy": "2025-11-26T17:49:50.157273Z",
     "iopub.status.idle": "2025-11-26T17:49:50.166166Z",
     "shell.execute_reply": "2025-11-26T17:49:50.165049Z"
    },
    "papermill": {
     "duration": 0.015885,
     "end_time": "2025-11-26T17:49:50.167876",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.151991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 6: Main 'Daemon' loop function defined.\n"
     ]
    }
   ],
   "source": [
    "def run_concierge_swarm(loop_delay_seconds: int):\n",
    "    \"\"\"\n",
    "    Main function to run the agent swarm (Loop Agent).\n",
    "    Simulates a \"daemon\" processing a queue of user commands.\n",
    "    Demonstrates: Loop, Long-Running Ops (Pause/Resume), Sequential, Parallel\n",
    "    \"\"\"\n",
    "    \n",
    "    log_message(\"KaggleConcierge\", \"Swarm is active. Monitoring command queue...\")\n",
    "    \n",
    "    # --- MOCKED COMMAND QUEUE ---\n",
    "    # This simulates a user giving commands to their assistant.\n",
    "    command_queue = [\n",
    "        {\"action\": \"new_project\", \"name\": \"Titanic\"},\n",
    "        {\"action\": \"new_project\", \"name\": \"House Prices\"},\n",
    "        {\"action\": \"download_dataset\", \"name\": \"Store Sales\"}, # Not a new project\n",
    "    ]\n",
    "    \n",
    "    # --- Clear dashboard file at the start ---\n",
    "    alert_filename = MEMORY_BANK[\"dashboard_file\"]\n",
    "    if os.path.exists(alert_filename):\n",
    "        os.remove(alert_filename)\n",
    "        log_message(\"KaggleConcierge\", \"Cleared old project dashboard.\")\n",
    "    # Create a blank one\n",
    "    tool_update_dashboard(MEMORY_BANK[\"projects\"], MEMORY_BANK[\"dashboard_file\"])\n",
    "\n",
    "\n",
    "    # --- Phase 1: The \"Daemon\" (Loop) ---\n",
    "    loop_count = 0\n",
    "    while command_queue:\n",
    "        loop_count += 1\n",
    "        log_message(\"KaggleConcierge\", f\"--- Starting Loop {loop_count} ---\")\n",
    "        \n",
    "        # Get the next item from the queue\n",
    "        command = command_queue.pop(0)\n",
    "        \n",
    "        # --- Phase 2: Planning (Sequential) ---\n",
    "        planned_task = planner_agent(command)\n",
    "        \n",
    "        # --- Phase 3: Parallel Execution ---\n",
    "        log_message(\"PlannerAgent\", f\"Spawning parallel agents for command...\")\n",
    "        \n",
    "        report_part_1 = folder_agent(planned_task[\"command\"])\n",
    "        report_part_2 = dataset_agent(planned_task[\"command\"])\n",
    "        \n",
    "        # --- Phase 4: Evaluation (Sequential \"Brain\") ---\n",
    "        brain_decision = dashboard_agent(\n",
    "            command=planned_task[\"command\"],\n",
    "            folder_report=report_part_1,\n",
    "            dataset_report=report_part_2\n",
    "        )\n",
    "        \n",
    "        # --- Phase 6: LONG-RUNNING OPERATION (PAUSE/RESUME) ---\n",
    "        if command_queue:\n",
    "            log_message(\"KaggleConcierge\", f\"Task complete. Pausing for {loop_delay_seconds}s...\")\n",
    "            time.sleep(loop_delay_seconds)\n",
    "            log_message(\"KaggleConcierge\", \"Resuming operation. Checking for new commands...\")\n",
    "    \n",
    "    log_message(\"KaggleConcierge\", \"All commands processed. Swarm is shutting down.\")\n",
    "\n",
    "print(\"Cell 6: Main 'Daemon' loop function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d30e84",
   "metadata": {
    "papermill": {
     "duration": 0.004292,
     "end_time": "2025-11-26T17:49:50.176532",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.172240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **9. ðŸš€ \"Putting in a Request!\" ðŸš€ (Run Swarm)**\n",
    "(This covers Cell 7: Run Swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac9bf71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:50.186372Z",
     "iopub.status.busy": "2025-11-26T17:49:50.186092Z",
     "iopub.status.idle": "2025-11-26T17:49:55.898236Z",
     "shell.execute_reply": "2025-11-26T17:49:55.896750Z"
    },
    "papermill": {
     "duration": 5.719445,
     "end_time": "2025-11-26T17:49:55.900062",
     "exception": false,
     "start_time": "2025-11-26T17:49:50.180617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Cleared Memory Bank for new run ---\n",
      "[2025-11-26 17:49:50] [KaggleConcierge] [INFO]: Swarm is active. Monitoring command queue...\n",
      "[2025-11-26 17:49:50] [DashboardTool] [INFO]: Updating stateful dashboard file: 'PROJECT_DASHBOARD.md'\n",
      "[2025-11-26 17:49:50] [DashboardTool] [INFO]: Dashboard successfully updated.\n",
      "[2025-11-26 17:49:50] [KaggleConcierge] [INFO]: --- Starting Loop 1 ---\n",
      "[2025-11-26 17:49:50] [PlannerAgent] [INFO]: New command received: new_project for 'Titanic'\n",
      "[2025-11-26 17:49:50] [PlannerAgent] [INFO]: Spawning parallel agents for command...\n",
      "[2025-11-26 17:49:50] [FolderAgent] [INFO]: Activating for project 'Titanic'\n",
      "[2025-11-26 17:49:50] [FileSystemTool] [INFO]: Creating folders for 'Titanic': /data, /notebooks, /submission\n",
      "[2025-11-26 17:49:50] [FolderAgent] [INFO]: Folder creation complete.\n",
      "[2025-11-26 17:49:50] [DatasetAgent] [INFO]: Activating for project 'Titanic'\n",
      "[2025-11-26 17:49:50] [NetworkTool] [INFO]: Downloading dataset 'Titanic' from Kaggle...\n",
      "[2025-11-26 17:49:50] [NetworkTool] [INFO]: Dataset saved to 'mock_data/titanic.csv'\n",
      "[2025-11-26 17:49:50] [DatasetAgent] [INFO]: Dataset download complete.\n",
      "[2025-11-26 17:49:50] [DashboardAgent] [INFO]: Synthesizing all reports for project 'Titanic'...\n",
      "[2025-11-26 17:49:50] [DashboardAgent] [INFO]: Generated new status: Project Ready. Data at: mock_data/titanic.csv\n",
      "[2025-11-26 17:49:50] [DashboardTool] [INFO]: Updating stateful dashboard file: 'PROJECT_DASHBOARD.md'\n",
      "[2025-11-26 17:49:50] [DashboardTool] [INFO]: Dashboard successfully updated.\n",
      "[2025-11-26 17:49:50] [KaggleConcierge] [INFO]: Task complete. Pausing for 2s...\n",
      "[2025-11-26 17:49:52] [KaggleConcierge] [INFO]: Resuming operation. Checking for new commands...\n",
      "[2025-11-26 17:49:52] [KaggleConcierge] [INFO]: --- Starting Loop 2 ---\n",
      "[2025-11-26 17:49:52] [PlannerAgent] [INFO]: New command received: new_project for 'House Prices'\n",
      "[2025-11-26 17:49:52] [PlannerAgent] [INFO]: Spawning parallel agents for command...\n",
      "[2025-11-26 17:49:52] [FolderAgent] [INFO]: Activating for project 'House Prices'\n",
      "[2025-11-26 17:49:52] [FileSystemTool] [INFO]: Creating folders for 'House Prices': /data, /notebooks, /submission\n",
      "[2025-11-26 17:49:52] [FolderAgent] [INFO]: Folder creation complete.\n",
      "[2025-11-26 17:49:52] [DatasetAgent] [INFO]: Activating for project 'House Prices'\n",
      "[2025-11-26 17:49:52] [NetworkTool] [INFO]: Downloading dataset 'House Prices' from Kaggle...\n",
      "[2025-11-26 17:49:53] [NetworkTool] [INFO]: Dataset saved to 'mock_data/house_prices.csv'\n",
      "[2025-11-26 17:49:53] [DatasetAgent] [INFO]: Dataset download complete.\n",
      "[2025-11-26 17:49:53] [DashboardAgent] [INFO]: Synthesizing all reports for project 'House Prices'...\n",
      "[2025-11-26 17:49:53] [DashboardAgent] [INFO]: Generated new status: Project Ready. Data at: mock_data/house_prices.csv\n",
      "[2025-11-26 17:49:53] [DashboardTool] [INFO]: Updating stateful dashboard file: 'PROJECT_DASHBOARD.md'\n",
      "[2025-11-26 17:49:53] [DashboardTool] [INFO]: Dashboard successfully updated.\n",
      "[2025-11-26 17:49:53] [KaggleConcierge] [INFO]: Task complete. Pausing for 2s...\n",
      "[2025-11-26 17:49:55] [KaggleConcierge] [INFO]: Resuming operation. Checking for new commands...\n",
      "[2025-11-26 17:49:55] [KaggleConcierge] [INFO]: --- Starting Loop 3 ---\n",
      "[2025-11-26 17:49:55] [PlannerAgent] [INFO]: New command received: download_dataset for 'Store Sales'\n",
      "[2025-11-26 17:49:55] [PlannerAgent] [INFO]: Spawning parallel agents for command...\n",
      "[2025-11-26 17:49:55] [FolderAgent] [INFO]: Activating for project 'Store Sales'\n",
      "[2025-11-26 17:49:55] [FolderAgent] [INFO]: No folder action required. Skipping.\n",
      "[2025-11-26 17:49:55] [DatasetAgent] [INFO]: Activating for project 'Store Sales'\n",
      "[2025-11-26 17:49:55] [NetworkTool] [INFO]: Downloading dataset 'Store Sales' from Kaggle...\n",
      "[2025-11-26 17:49:55] [NetworkTool] [INFO]: Dataset saved to 'mock_data/store_sales.csv'\n",
      "[2025-11-26 17:49:55] [DatasetAgent] [INFO]: Dataset download complete.\n",
      "[2025-11-26 17:49:55] [DashboardAgent] [INFO]: Synthesizing all reports for project 'Store Sales'...\n",
      "[2025-11-26 17:49:55] [DashboardAgent] [INFO]: Generated new status: Data Ready. Path: mock_data/store_sales.csv\n",
      "[2025-11-26 17:49:55] [DashboardTool] [INFO]: Updating stateful dashboard file: 'PROJECT_DASHBOARD.md'\n",
      "[2025-11-26 17:49:55] [DashboardTool] [INFO]: Dashboard successfully updated.\n",
      "[2025-11-26 17:49:55] [KaggleConcierge] [INFO]: All commands processed. Swarm is shutting down.\n",
      "\n",
      "\n",
      "========================================\n",
      "âœ… SWARM RUN COMPLETE âœ…\n",
      "Total Tasks Completed: 3\n",
      "Dashboard file 'PROJECT_DASHBOARD.md' is up to date.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "LOOP_DELAY_SECONDS = 2 # How long to \"pause\" (2s for demo)\n",
    "\n",
    "# --- Clear the memory from previous runs ---\n",
    "MEMORY_BANK[\"projects\"] = {}\n",
    "MEMORY_BANK[\"tasks_completed\"] = 0\n",
    "print(\"--- Cleared Memory Bank for new run ---\")\n",
    "\n",
    "# --- Run the entire agent swarm ---\n",
    "run_concierge_swarm(\n",
    "    loop_delay_seconds=LOOP_DELAY_SECONDS\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*40)\n",
    "print(\"âœ… SWARM RUN COMPLETE âœ…\")\n",
    "# --- FIX: Corrected MEMORY_BODY to MEMORY_BANK ---\n",
    "print(f\"Total Tasks Completed: {MEMORY_BANK['tasks_completed']}\")\n",
    "print(f\"Dashboard file '{MEMORY_BANK['dashboard_file']}' is up to date.\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e05eef",
   "metadata": {
    "papermill": {
     "duration": 0.004563,
     "end_time": "2025-11-26T17:49:55.909960",
     "exception": false,
     "start_time": "2025-11-26T17:49:55.905397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **10. \"Checking the Files\": (Reviewing the Memory)**\n",
    "(This covers Cell 8: Memory Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30c5b6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:55.920502Z",
     "iopub.status.busy": "2025-11-26T17:49:55.920201Z",
     "iopub.status.idle": "2025-11-26T17:49:55.926548Z",
     "shell.execute_reply": "2025-11-26T17:49:55.924912Z"
    },
    "papermill": {
     "duration": 0.013592,
     "end_time": "2025-11-26T17:49:55.928152",
     "exception": false,
     "start_time": "2025-11-26T17:49:55.914560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Long-Term Memory (Python Dictionary)...\n",
      "\n",
      "--- Project Status Dictionary (Written by 'DashboardAgent') ---\n",
      "Total projects tracked: 3\n",
      "{\n",
      "  \"Titanic\": \"Project Ready. Data at: mock_data/titanic.csv\",\n",
      "  \"House Prices\": \"Project Ready. Data at: mock_data/house_prices.csv\",\n",
      "  \"Store Sales\": \"Data Ready. Path: mock_data/store_sales.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting Long-Term Memory (Python Dictionary)...\")\n",
    "print(f\"\\n--- Project Status Dictionary (Written by 'DashboardAgent') ---\")\n",
    "print(f\"Total projects tracked: {len(MEMORY_BANK['projects'])}\")\n",
    "print(json.dumps(MEMORY_BANK['projects'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a202d",
   "metadata": {
    "papermill": {
     "duration": 0.00508,
     "end_time": "2025-11-26T17:49:55.938272",
     "exception": false,
     "start_time": "2025-11-26T17:49:55.933192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **11. ðŸ”” \"Your Dashboard is Ready!\" ðŸ”” (The Final File)**\n",
    "(This covers Cell 9: Final File Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243c8db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T17:49:55.949812Z",
     "iopub.status.busy": "2025-11-26T17:49:55.949534Z",
     "iopub.status.idle": "2025-11-26T17:49:55.957055Z",
     "shell.execute_reply": "2025-11-26T17:49:55.955903Z"
    },
    "papermill": {
     "duration": 0.01529,
     "end_time": "2025-11-26T17:49:55.958651",
     "exception": false,
     "start_time": "2025-11-26T17:49:55.943361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting 'PROJECT_DASHBOARD.md' file (created by Custom Tool)...\n",
      "================================================================================\n",
      "\n",
      "# ðŸ¤– Kaggle-Concierge Project Dashboard\n",
      "\n",
      "Current status of all data science projects.\n",
      "\n",
      "| Project Name | Status |\n",
      "| :--- | :--- |\n",
      "| **Titanic** | Project Ready. Data at: mock_data/titanic.csv |\n",
      "| **House Prices** | Project Ready. Data at: mock_data/house_prices.csv |\n",
      "| **Store Sales** | Data Ready. Path: mock_data/store_sales.csv |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inspecting '{MEMORY_BANK['dashboard_file']}' file (created by Custom Tool)...\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "alert_filename = MEMORY_BANK[\"dashboard_file\"]\n",
    "try:\n",
    "    with open(alert_filename, 'r') as f:\n",
    "        print(f.read())\n",
    "except FileNotFoundError:\n",
    "    print(f\"--- No file found. (This is OK if no projects were started) ---\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.546772,
   "end_time": "2025-11-26T17:49:56.384048",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T17:49:44.837276",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
